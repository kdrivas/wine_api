from hyperopt import fmin, hp, tpe, rand

import mlflow.projects
from mlflow.tracking.client import MlflowClient

from fire import Fire

def train_fn(null_train_loss, null_valid_loss):
  # Actual training function
    def train(params):
        max_depth, min_samples_leaf = params
        with mlflow.start_run(nested=True) as child_run:
          # run the training Step and wait it finishes
                p = mlflow.projects.run(
                uri=".",
                entry_point="train",
                run_id=child_run.info.run_id,
                parameters={
                    "data": data,
                    "epochs": str(epochs),
                    "min_samples_leaf": str(min_samples_leaf),
                    "target_col": target_col,
                    "max_depth": str(max_depth),
                    "random_state": "0"
                    },
                experiment_id=experiment_id,
                use_conda=False,
                synchronous=False
                )
            succeeded = p.wait()
        # If training finished successfully log the metrics
        if succeeded:
            training_run = tracking_client.get_run(p.run_id)
            metrics = training_run.data.metrics
            train_loss = metrics["train_{}".format(metric)]
            valid_loss = metrics["val_{}".format(metric)]
        else:
            # reported failed run
            tracking_client.set_terminated(p.run_id, "FAILED")
            train_loss = null_train_loss
            valid_loss = null_valid_loss
        # log the metrics from this run
        mlflow.log_metrics({
          "train_{}".format(metric): train_loss,
          "val_{}".format(metric)  : valid_loss
        })
        # return validation loss which will be used by the optimization algorithm
        return valid_loss
    return train

def search(data, max_runs, metric, algo):
    tracking_client = mlflow.tracking.MlflowClient()
    _inf = np.finfo(np.float64).max
    
    space = [
        hp.quniform('max_depth', 2, 12, 1)
        hp.quniform('min_samples_leaf', 2, 20, 1)
    ]
    
    with mlflow.start_run() as run:
        exp_id = run.info.experiment_id

        best = fmin(
          fn=train_fn(exp_id, _inf, _inf),
          space=space,
          algo=tpe.suggest if algo == "tpe.suggest" else rand.suggest,
          max_evals=max_runs
          )
        mlflow.set_tag("best params", str(best))
        # find all runs generated by this search
        client = MlflowClient()
        query = "tags.mlflow.parentRunId = '{run_id}' ".format(run_id=run.info.run_id)
        runs = client.search_runs([exp_id], query)
        # iterate over all runs to find best one
        best_train, best_valid = _inf, _inf
        best_run = None
        for r in runs:
            if r.data.metrics["val_auc"] < best_val_valid:
                best_run = r
                best_train = r.data.metrics["train_auc"]
                best_valid = r.data.metrics["val_auc"]
        # log best run metrics as the final metrics of this run.
        mlflow.set_tag("best_run", best_run.info.run_id)
        mlflow.log_metrics({
          "train_{}".format(metric): best_train,
          "val_{}".format(metric): best_valid
          })
        
if __name__ == '__main__':
    search()